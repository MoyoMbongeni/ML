{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPlf2KRjVb9CZCWliY/4hJr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoyoMbongeni/ML/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Help From Gemini"
      ],
      "metadata": {
        "id": "8g982_jnbDNi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "39rdi5OyZrji",
        "outputId": "08677b30-e8d5-4839-fbff-7dc278715bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wfdb\n",
            "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.13.2)\n",
            "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2025.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from wfdb) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.0.2)\n",
            "Collecting pandas>=2.2.3 (from wfdb)\n",
            "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from wfdb) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (1.16.3)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->wfdb) (1.22.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->wfdb) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.8.1->wfdb) (2025.11.12)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.10.0->wfdb) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\n",
            "Downloading wfdb-4.3.0-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pandas, wfdb\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.3.3 wfdb-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wfdb\n",
        "\n",
        "import numpy as np\n",
        "import wfdb\n",
        "import pywt\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Global Configuration\n",
        "FS = 360\n",
        "SEGMENT_LEN = 1800  # 5 seconds @ 360Hz\n",
        "NOISE_TYPES = ['baseline_wander', 'muscle_artifact', 'electrode_motion']\n",
        "\n",
        "def download_data():\n",
        "    \"\"\"Downloads necessary datasets if not present.\"\"\"\n",
        "    # Clean signals from MIT-BIH\n",
        "    wfdb.dl_database('mitdb', dl_dir='data/mitdb', records=['100', '101'])\n",
        "    # Noisy signals from NSTDB\n",
        "    wfdb.dl_database('nstdb', dl_dir='data/nstdb', records=['bw', 'ma', 'em'])\n",
        "\n",
        "def load_and_segment(record_path, label_idx=None):\n",
        "    \"\"\"Loads a record and slices it into 5s windows.\"\"\"\n",
        "    record = wfdb.rdrecord(record_path)\n",
        "    signal = record.p_signal[:, 0]  # Use Lead II/first channel\n",
        "\n",
        "    # Resample if not 360Hz (MIT-BIH and NSTDB are already 360Hz)\n",
        "\n",
        "    # Normalization (Min-Max 0-1)\n",
        "    scaler = MinMaxScaler()\n",
        "    signal = scaler.fit_transform(signal.reshape(-1, 1)).flatten()\n",
        "\n",
        "    segments = [signal[i:i + SEGMENT_LEN] for i in range(0, len(signal) - SEGMENT_LEN, SEGMENT_LEN)]\n",
        "    return np.array(segments)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(signal):\n",
        "    \"\"\"\n",
        "    Extracts 15 features for SVM:\n",
        "    - DWT (db4, Level 9): Energy and Std Dev of last 6 bands (12 features)\n",
        "    - TERMA: Peak, Mean, Std of moving average difference (3 features)\n",
        "    \"\"\"\n",
        "    # DWT: Level 9 to capture very low-freq Baseline Wander\n",
        "    coeffs = pywt.wavedec(signal, 'db4', level=9)\n",
        "    dwt_feats = []\n",
        "    for c in coeffs[-6:]: # Last 6 bands (approx + 5 details)\n",
        "        dwt_feats.append(np.sqrt(np.mean(c**2))) # Energy\n",
        "        dwt_feats.append(np.std(c))              # Std Dev\n",
        "\n",
        "    # TERMA: Moving Average Difference\n",
        "    sq_sig = signal**2\n",
        "    fast_ma = np.convolve(sq_sig, np.ones(18)/18, mode='same')\n",
        "    slow_ma = np.convolve(sq_sig, np.ones(360)/360, mode='same')\n",
        "    terma_sig = fast_ma - slow_ma\n",
        "\n",
        "    terma_feats = [np.max(terma_sig), np.mean(terma_sig), np.std(terma_sig)]\n",
        "\n",
        "    return np.concatenate([dwt_feats, terma_feats])"
      ],
      "metadata": {
        "id": "JzQNgU7JaM80"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def build_1d_cnn():\n",
        "    model = models.Sequential([\n",
        "        # Raw Signal Input (1800, 1)\n",
        "        layers.Input(shape=(SEGMENT_LEN, 1)),\n",
        "\n",
        "        layers.Conv1D(32, kernel_size=15, activation='relu'),\n",
        "        layers.MaxPooling1D(2),\n",
        "\n",
        "        layers.Conv1D(64, kernel_size=10, activation='relu'),\n",
        "        layers.MaxPooling1D(2),\n",
        "\n",
        "        layers.Conv1D(64, kernel_size=5, activation='relu'),\n",
        "        layers.GlobalAveragePooling1D(), # Efficiency for Colab\n",
        "\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        # Multi-label output (Sigmoid)\n",
        "        layers.Dense(len(NOISE_TYPES), activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "u9Q6ZMZhaiT6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_signal(raw_segment, cnn_model, svm_model):\n",
        "    \"\"\"\n",
        "    Processes a segment through both systems and ranks severity.\n",
        "    \"\"\"\n",
        "    # 1. CNN Prediction (Direct)\n",
        "    cnn_input = raw_segment.reshape(1, SEGMENT_LEN, 1)\n",
        "    cnn_probs = cnn_model.predict(cnn_input, verbose=0)[0]\n",
        "\n",
        "    # 2. Mapping to output format\n",
        "    detected = {}\n",
        "    severity = {}\n",
        "\n",
        "    for i, name in enumerate(NOISE_TYPES):\n",
        "        prob = cnn_probs[i]\n",
        "        is_detected = prob > 0.5\n",
        "        detected[name] = bool(is_detected)\n",
        "        if is_detected:\n",
        "            # Using probability as a proxy for severity %\n",
        "            severity[name] = round(prob * 100, 1)\n",
        "\n",
        "    # 3. Quality Assessment\n",
        "    if not severity:\n",
        "        dominant = 'None'\n",
        "        quality = 'excellent'\n",
        "    else:\n",
        "        dominant = max(severity, key=severity.get)\n",
        "        max_sev = severity[dominant]\n",
        "        if max_sev < 40: quality = 'high'\n",
        "        elif max_sev < 75: quality = 'moderate'\n",
        "        else: quality = 'low'\n",
        "\n",
        "    return {\n",
        "        'detected_noises': detected,\n",
        "        'severity_scores': severity,\n",
        "        'dominant_noise': dominant,\n",
        "        'overall_quality': quality\n",
        "    }"
      ],
      "metadata": {
        "id": "0LxT906_awHW"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}